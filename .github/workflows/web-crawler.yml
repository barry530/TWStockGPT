name: Web Crawler
run-name: Monthly Revenue and seasonal reports

# trigger time
on:
  schedule: 
    - cron: "0 23 * * *"  # UTC -> At 23:00 every day
  workflow_dispatch:  # allow manual action

env:
  DB_CONNECTION: ${{ secrets.GCP_MYSQL_CONFIG }}

# Define the action
jobs:
  financial-reports-crawler:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Install Python Dependencies
        run: pip install pandas requests lxml google google-api-python-client html5lib pymysql
      - name: Run the Crawler Script
        run: python ./src/main_crawler.py
      - name: Commit Data Back to Github Repo
        run: |
          git config --global user.name "monthly-revenue-crawler"
          git config --global user.email "monthly-revenue-crawler@gmail.com"
          git add . && git commit -m "financial report crawler"
          git push origin main
      - name: End
        run: echo 'Done!'
  
